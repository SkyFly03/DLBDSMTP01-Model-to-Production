# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# app/train_eval.py
# ------------------------------------------------------------
# Training & Evaluation
# - Generate fictional sensor data (temp, humidity, sound_volume)
# - 70/10/20 split (Train/Val/Test), train IsolationForest via model.py
# - Export: metrics_table.png, heatmaps_grid.png, score_distributions.png
# - 2×2 learning dashboard: ROC(Test) + F1 curves + size/sweep plots
# - Per-feature anomalies over time (5-min buckets) from predictions_log.csv
# ------------------------------------------------------------
from __future__ import annotations

import os
import json
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg") 
import matplotlib.pyplot as plt

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, confusion_matrix
)
from sklearn.utils import shuffle
try:
    # When running as a module: python -m app.train_eval
    from app.model import TurbineAnomalyDetector
except ImportError:
    # When running directly: python app/train_eval.py
    from model import TurbineAnomalyDetector

OUT_DIR = os.path.join("app", "outputs")
os.makedirs(OUT_DIR, exist_ok=True)


# -------------------------
# Data generation & split
# -------------------------
def make_fictional_sensor_data(n: int = 3000, seed: int = 42) -> tuple[pd.DataFrame, np.ndarray]:
    rng = np.random.default_rng(seed)
    k_anom = max(1, int(0.05 * n))
    k_norm = n - k_anom

    temp_n = rng.normal(25, 3, k_norm)
    hum_n = rng.normal(60, 8, k_norm)
    snd_n = rng.normal(0.5, 0.1, k_norm)

    temp_a = rng.choice([rng.normal(45, 3, k_anom), rng.normal(10, 3, k_anom)]).copy()
    hum_a = rng.choice([rng.normal(90, 5, k_anom), rng.normal(20, 5, k_anom)]).copy()
    snd_a = rng.choice([rng.normal(1.2, 0.1, k_anom), rng.normal(0.1, 0.05, k_anom)]).copy()

    X = pd.DataFrame({
        "temperature": np.concatenate([temp_n, temp_a]),
        "humidity": np.concatenate([hum_n, hum_a]),
        "sound_volume": np.concatenate([snd_n, snd_a]),
    })
    y = np.array([0] * k_norm + [1] * k_anom, dtype=int)
    X, y = shuffle(X, y, random_state=seed)
    return X.reset_index(drop=True), y


def split_70_10_20(X: pd.DataFrame, y: np.ndarray, seed: int = 42):
    n = len(X)
    n_train = int(0.7 * n)
    n_val = int(0.1 * n)
    idx = np.arange(n)
    rng = np.random.default_rng(seed)
    rng.shuffle(idx)

    i_tr = idx[:n_train]
    i_va = idx[n_train:n_train + n_val]
    i_te = idx[n_train + n_val:]
    return (X.iloc[i_tr].reset_index(drop=True), X.iloc[i_va].reset_index(drop=True),
            X.iloc[i_te].reset_index(drop=True), y[i_tr], y[i_va], y[i_te])


# -------------------------
# Metrics & small utilities
# -------------------------
def compute_metrics(y_true, scores, yhat, split_name):
    return {
        "Split": split_name,
        "Accuracy": accuracy_score(y_true, yhat),
        "Precision": precision_score(y_true, yhat, zero_division=0),
        "Recall": recall_score(y_true, yhat, zero_division=0),
        "F1": f1_score(y_true, yhat, zero_division=0),
        "ROC_AUC": roc_auc_score(y_true, scores),
    }


def _save_table_csv(df: pd.DataFrame, name: str):
    path = os.path.join(OUT_DIR, name)
    df.to_csv(path, index=False)
    return path


def plot_score_distributions(det: TurbineAnomalyDetector, splits: dict):
    """
    Histogram (density) of anomaly_score for Train/Val/Test.
    Robust to DataFrame/dict/tuple/ndarray returns from det.predict.
    """
    def _extract_scores(pred_out):
        if isinstance(pred_out, pd.DataFrame) and "anomaly_score" in pred_out.columns:
            return pred_out["anomaly_score"].to_numpy()
        if isinstance(pred_out, dict) and "anomaly_score" in pred_out:
            return np.asarray(pred_out["anomaly_score"])
        if isinstance(pred_out, (list, tuple)) and len(pred_out) > 0:
            return np.asarray(pred_out[0])
        arr = np.asarray(pred_out)
        return arr[:, 0] if arr.ndim == 2 and arr.shape[1] >= 1 else arr

    colors = {"Train": "#56B4E9", "Val": "#E69F00", "Test": "#D55E00"}  # color-blind–safe
    # Get all scores once to set a common bin range
    all_scores = []
    per_split = {}
    for name, (Xsplit, _) in splits.items():
        s = _extract_scores(det.predict(Xsplit))
        per_split[name] = s
        if s.size:
            all_scores.append(s)
    if all_scores:
        all_scores = np.concatenate(all_scores)
        smin, smax = np.min(all_scores), np.max(all_scores)
    else:
        smin, smax = -1.0, 1.0  # fallback

    plt.figure(figsize=(10, 5))
    for name, s in per_split.items():
        if s.size:
            plt.hist(s, bins=40, range=(smin, smax), density=True,
                     alpha=0.35, label=name, color=colors.get(name))

    plt.title("Anomaly Score Distributions (density)")
    plt.xlabel("anomaly_score (higher = more anomalous)")
    plt.ylabel("density")
    plt.legend()

    # Format x-axis as European date + time: DD-MM-YY HH:MM
    import matplotlib.dates as mdates
    ax = plt.gca()
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%y %H:%M'))
    ax.xaxis.set_major_locator(mdates.AutoDateLocator(minticks=6, maxticks=12))
    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')

# -------------------------
# Visuals
# -------------------------
def plot_heatmaps_grid(X, yval, yhat_val, yte, yhat_te, split_label):
    import itertools, numpy as np

    fig, axes = plt.subplots(1, 3, figsize=(12, 3))

    # ---- Correlation heatmap (robust to bad dtypes / NaNs) ----
    ax = axes[0]
    cols = [c for c in ["temperature", "humidity", "sound_volume"] if c in X.columns]

    # Coerce to numeric, handle NaNs
    df_num = X[cols].apply(pd.to_numeric, errors="coerce")
    # Drop rows that are all-NaN across the three features
    df_num = df_num.dropna(how="all")
    # Fill remaining NaNs with column means (if any)
    if not df_num.empty:
        df_num = df_num.fillna(df_num.mean(numeric_only=True))

    # Compute correlation or fall back to identity
    if df_num.shape[0] >= 2 and len(cols) >= 2:
        corr = df_num.corr().to_numpy()
    else:
        # Not enough data — use identity so the plot is still informative
        n = max(1, len(cols))
        corr = np.eye(n)

    im = ax.imshow(corr, cmap="coolwarm", vmin=-1, vmax=1)
    ax.set_xticks(range(len(cols)))
    ax.set_xticklabels(cols, rotation=45, ha="right")
    ax.set_yticks(range(len(cols)))
    ax.set_yticklabels(cols)
    ax.set_title("Correlation heatmap")

    # Annotate each cell with the numeric value
    for i in range(len(cols)):
        for j in range(len(cols)):
            val = corr[i, j]
            if np.isfinite(val):
                ax.text(j, i, f"{val:.2f}", ha="center", va="center", color="#111")

    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

    # ---- Confusion matrices (Val/Test) ----
    def _conf(ax, y, yhat, ttl):
        y = np.asarray(y).astype(int)
        yhat = np.asarray(yhat).astype(int)
        cm = confusion_matrix(y, yhat, labels=[0, 1])
        im = ax.imshow(cm, cmap="Blues")
        for i, j in itertools.product(range(2), range(2)):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center", color="#111")
        ax.set_xticks([0, 1]); ax.set_yticks([0, 1])
        ax.set_xticklabels(["Normal", "Anomaly"])
        ax.set_yticklabels(["Normal", "Anomaly"])
        ax.set_xlabel("Predicted"); ax.set_ylabel("True")
        ax.set_title(ttl)
        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)

    _conf(axes[1], yval, yhat_val, "Confusion (Val)")
    _conf(axes[2], yte,  yhat_te,  "Confusion (Test)")

    plt.suptitle(split_label, y=1.02, fontsize=12)
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, "heatmaps_grid.png"), dpi=150, bbox_inches="tight")
    plt.close()

def plot_feature_histograms_by_label(X: pd.DataFrame, y: np.ndarray, bins: int = 40):
    """
    Three side-by-side histograms showing normal vs anomaly for:
      - temperature (°C)
      - humidity (%)
      - sound_volume (arb)
    Colors: normal=blue (#56B4E9), anomaly=orange (#E69F00)
    Saves: app/outputs/histograms.png
    """
    # Make a clean numeric copy (in case anything came from CSV)
    cols = ["temperature", "humidity", "sound_volume"]
    Xp = X.copy()
    for c in cols:
        Xp[c] = pd.to_numeric(Xp[c], errors="coerce")
    mask = ~Xp[cols].isna().any(axis=1)
    Xp = Xp.loc[mask].reset_index(drop=True)
    yp = np.asarray(y)[mask.values]

    normal = Xp[yp == 0]
    anom   = Xp[yp == 1]

    # Okabe–Ito color-blind friendly
    C_NORMAL = "#56B4E9"  # blue
    C_ANOM   = "#E69F00"  # orange

    fig, axes = plt.subplots(1, 3, figsize=(12, 3), sharey=True)
    specs = [
        ("temperature",  "Temperature (°C)"),
        ("humidity",     "Humidity (%)"),
        ("sound_volume", "Sound volume (arb)"),
    ]

    for ax, (col, xlab) in zip(axes, specs):
        # normal
        ax.hist(
            normal[col].to_numpy(),
            bins=bins, alpha=0.85, color=C_NORMAL,
            edgecolor="white", linewidth=0.4, label="normal"
        )
        # anomaly
        ax.hist(
            anom[col].to_numpy(),
            bins=bins, alpha=0.85, color=C_ANOM,
            edgecolor="white", linewidth=0.4, label="anomaly"
        )

        ax.set_title(col)
        ax.set_xlabel(xlab)
        ax.grid(True, alpha=0.25)
        ax.legend(frameon=False)

    axes[0].set_ylabel("count")
    fig.suptitle("", y=1.02)  # no big title to match your reference style
    fig.tight_layout()
    fig.savefig(os.path.join(OUT_DIR, "histograms.png"), dpi=150, bbox_inches="tight")
    plt.close(fig)

def learning_dashboard_2x2_v2(Xtr, ytr, Xval, yval, Xte, yte, contamination=0.05):
    fig, axes = plt.subplots(2, 2, figsize=(10, 8))
    base = TurbineAnomalyDetector(contamination=contamination, n_estimators=100, random_state=42)
    base.train(Xtr)

    def _scores(pred_out):
        if isinstance(pred_out, pd.DataFrame) and "anomaly_score" in pred_out.columns:
            return pred_out["anomaly_score"].to_numpy()
        if isinstance(pred_out, dict) and "anomaly_score" in pred_out:
            return np.asarray(pred_out["anomaly_score"])
        if isinstance(pred_out, (list, tuple)) and len(pred_out) > 0:
            return np.asarray(pred_out[0])
        arr = np.asarray(pred_out)
        return arr[:, 0] if arr.ndim == 2 and arr.shape[1] >= 1 else arr

    s_tr = _scores(base.predict(Xtr))
    s_va = _scores(base.predict(Xval))
    s_te = _scores(base.predict(Xte))

    ax = axes[0, 0]
    fpr, tpr, _ = roc_curve(yte, s_te)
    auc = roc_auc_score(yte, s_te)
    ax.plot(fpr, tpr, linewidth=2)
    ax.plot([0, 1], [0, 1], "--")
    ax.set_title(f"ROC (Test)  AUC = {auc:.3f}")
    ax.set_xlabel("FPR")
    ax.set_ylabel("TPR")
    ax.grid(True, alpha=0.3)

    def _smooth(y, k=7):
        return np.convolve(y, np.ones(k) / k, mode="same") if len(y) >= k else y

    ax = axes[0, 1]
    tmin, tmax = min(s_tr.min(), s_va.min(), s_te.min()), max(s_tr.max(), s_va.max(), s_te.max())
    ts = np.linspace(tmin, tmax, 300)

    def _f1s(scores, y):
        return np.array([f1_score(y, (scores >= t).astype(int), zero_division=0) for t in ts])

    ax.plot(ts, _smooth(_f1s(s_tr, ytr)), label="Train", linewidth=2)
    ax.plot(ts, _smooth(_f1s(s_va, yval)), label="Val", linewidth=2)
    ax.plot(ts, _smooth(_f1s(s_te, yte)), label="Test", linewidth=2)
    ax.set_title("F1 vs threshold — Train / Val / Test")
    ax.set_xlabel("anomaly_score threshold")
    ax.set_ylabel("F1")
    ax.grid(True, alpha=0.3)
    ax.legend()

    ax = axes[1, 0]
    fracs = np.linspace(0.1, 1.0, 12)
    f1_curve = []
    for f in fracs:
        n = max(50, int(len(Xtr) * f))
        d = TurbineAnomalyDetector(contamination=contamination, n_estimators=100, random_state=42)
        d.train(Xtr.iloc[:n])
        scores_val = _scores(d.predict(Xval))
        f1_curve.append(f1_score(yval, (scores_val >= 0).astype(int), zero_division=0))

    ax.plot(fracs, _smooth(np.array(f1_curve), 3), marker="o")
    ax.set_title("Val F1 vs fraction of train")
    ax.set_xlabel("fraction of train")
    ax.set_ylabel("F1")
    ax.grid(True, alpha=0.3)

    ax = axes[1, 1]
    est_list = [25, 50, 100, 150, 200, 300]
    f1_est = []
    for n in est_list:
        d = TurbineAnomalyDetector(contamination=contamination, n_estimators=n, random_state=42)
        d.train(Xtr)
        scores_val = _scores(d.predict(Xval))
        f1_est.append(f1_score(yval, (scores_val >= 0).astype(int), zero_division=0))

    ax.plot(est_list, _smooth(np.array(f1_est), 3), marker="o")
    ax.set_title("Val F1 vs n_estimators")
    ax.set_xlabel("n_estimators")
    ax.set_ylabel("F1")
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, "learning_dashboard_2x2.png"), dpi=150)
    plt.close()


def plot_feature_anomalies_over_time(
    log_path: str,
    ref_means: dict | None = None,
    ref_stds: dict | None = None,
    window_minutes: int = 5,
    smooth_points: int = 3,
    hours_back: int | None = None,     # kept for backward compat
    start_at: str | None = None,       # e.g., "2025-10-13"
    end_at: str | None = None,         # e.g., "2025-10-13 23:59:59"
):
    """
    Build per-feature anomaly counts over time from predictions_log.csv.

    Robustness:
    - Parses timestamps and coerces feature columns to numeric.
    - If hours_back is set, windows relative to the log's latest timestamp (not now),
      so older logs still render.
    - If ref_means/ref_stds are None, computes baselines from the log itself
      (prefer is_anomaly==0 rows if present, else all rows).
    - Buckets by N minutes and draws 3 colored lines (temperature, humidity, sound_volume).
    """
    if not os.path.exists(log_path):
        return

    df = pd.read_csv(log_path)

    # --- Parse timestamp robustly ---
    if "timestamp" not in df.columns:
        return
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
    df = df.dropna(subset=["timestamp"])
    # make tz-naive for plotting
    df["timestamp"] = df["timestamp"].dt.tz_convert(None)

    # --- Coerce features to numeric ---
    for col in ["temperature", "humidity", "sound_volume"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        else:
            # if any feature missing, bail gracefully
            return
    df = df.dropna(subset=["temperature", "humidity", "sound_volume"])

    # --- Window selection ---
    if start_at or end_at:
        if start_at:
            start_ts = pd.to_datetime(start_at, utc=True).tz_convert(None)
            df = df[df["timestamp"] >= start_ts]
        if end_at:
            end_ts = pd.to_datetime(end_at, utc=True).tz_convert(None)
            df = df[df["timestamp"] <= end_ts]
    elif hours_back is not None and len(df) > 0:
        latest = df["timestamp"].max()
        cutoff = latest - pd.Timedelta(hours=hours_back)
        df = df[df["timestamp"] >= cutoff]
    if df.empty:
        # Write an empty-but-informative plot instead of failing silently
        plt.figure(figsize=(12, 3))
        plt.title("Anomalies over time — no data in selected window")
        plt.xlabel("time"); plt.ylabel("count")
        plt.tight_layout()
        plt.savefig(os.path.join(OUT_DIR, "anomalies_over_time.png"), dpi=150, bbox_inches="tight")
        plt.close()
        return

    # --- Choose baseline (means/stds) ---
    if ref_means is None or ref_stds is None:
        # Prefer normal rows if a label exists
        base = df
        if "is_anomaly" in df.columns:
            try:
                base = df[df["is_anomaly"].astype(int) == 0]
                if base.empty:
                    base = df
            except Exception:
                base = df
        ref_means = {c: float(base[c].mean()) for c in ["temperature","humidity","sound_volume"]}
        ref_stds  = {c: float(base[c].std(ddof=0) or 1e-9) for c in ["temperature","humidity","sound_volume"]}

    # --- Per-feature anomaly flags by z-score ---
    g = df[["timestamp","temperature","humidity","sound_volume"]].copy().set_index("timestamp").sort_index()
    out = pd.DataFrame(index=g.index)
    for c in ["temperature","humidity","sound_volume"]:
        mu = float(ref_means[c]); sd = max(float(ref_stds[c]), 1e-9)
        out[c] = ((g[c] - mu).abs() / sd > 3).astype(int)

    # --- Resample to N-minute buckets ---
    per = out.resample(f"{window_minutes}min").sum().reset_index()
    if per.empty:
        # Ensure we still save a file
        plt.figure(figsize=(12, 3))
        plt.title(f"Anomalies over time ({window_minutes}-minute buckets) — no buckets")
        plt.xlabel("time"); plt.ylabel("count")
        plt.tight_layout()
        plt.savefig(os.path.join(OUT_DIR, "anomalies_over_time.png"), dpi=150, bbox_inches="tight")
        plt.close()
        return

    # --- Plot 3 lines with light smoothing ---
    plt.figure(figsize=(12, 4))
    palette = {
        "temperature": "#E69F00",  # orange
        "humidity":    "#0072B2",  # blue
        "sound_volume":"#009E73",  # green
    }
    for c in ["temperature","humidity","sound_volume"]:
        y = per[c].to_numpy()
        if smooth_points and len(y) >= smooth_points:
            y = np.convolve(y, np.ones(smooth_points)/smooth_points, mode="same")
        plt.plot(per["timestamp"], y, label=c, linewidth=2, color=palette[c])
    
    # Format x-axis as DD-MM-YY HH:MM
    import matplotlib.dates as mdates
    ax = plt.gca()
    ax.xaxis.set_major_locator(mdates.AutoDateLocator(minticks=6, maxticks=12))
    ax.xaxis.set_major_formatter(mdates.DateFormatter("%d-%m-%y %H:%M"))
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

    plt.title(f"Anomalies over time ({window_minutes}-minute buckets) — per feature")
    plt.xlabel("time"); plt.ylabel("count")
    plt.grid(True, alpha=0.3); plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, "anomalies_over_time.png"), dpi=150, bbox_inches="tight")
    plt.close()

def render_metrics_table_image(df, title, out_path):
    fmt = df.copy()
    for c in fmt.columns:
        if pd.api.types.is_numeric_dtype(fmt[c]):
            fmt[c] = fmt[c].map(lambda x: f"{float(x):.3f}")
        else:
            fmt[c] = fmt[c].astype(str)

    fig, ax = plt.subplots(figsize=(10, 3))
    ax.axis("off")
    ax.set_title(title, pad=12, fontsize=12)
    tbl = ax.table(cellText=fmt.values, colLabels=fmt.columns, loc="center")
    tbl.auto_set_font_size(False)
    tbl.set_fontsize(9)
    tbl.scale(1, 1.2)
    plt.tight_layout()
    plt.savefig(out_path, dpi=150, bbox_inches="tight")
    plt.close(fig)


def main():
    X, y = make_fictional_sensor_data(n=9800, seed=42)
    Xtr, Xval, Xte, ytr, yval, yte = split_70_10_20(X, y)
    SPLIT_LABEL = "70% Train / 10% Val / 20% Test"
    plot_feature_histograms_by_label(X, y)

    det = TurbineAnomalyDetector(contamination=0.05, n_estimators=100, random_state=42)
    det.train(Xtr)

    res_tr, res_va, res_te = det.predict(Xtr), det.predict(Xval), det.predict(Xte)
    dfm = pd.DataFrame([
        compute_metrics(ytr, res_tr["anomaly_score"], res_tr["is_anomaly"], "Train"),
        compute_metrics(yval, res_va["anomaly_score"], res_va["is_anomaly"], "Val"),
        compute_metrics(yte, res_te["anomaly_score"], res_te["is_anomaly"], "Test"),
    ])
    _save_table_csv(dfm, "metrics_table.csv")
    render_metrics_table_image(
        dfm[["Split", "Accuracy", "Precision", "Recall", "F1", "ROC_AUC"]],
        f"Model metrics — {SPLIT_LABEL}",
        os.path.join(OUT_DIR, "metrics_table.png")
    )

    plot_heatmaps_grid(X, yval, res_va["is_anomaly"], yte, res_te["is_anomaly"], SPLIT_LABEL)

    learning_dashboard_2x2_v2(Xtr, ytr, Xval, yval, Xte, yte)

    ref_means = Xtr.mean().to_dict()
    ref_stds = Xtr.std(ddof=0).to_dict()
    plot_feature_anomalies_over_time(
        os.path.join(OUT_DIR, "predictions_log.csv"), ref_means, ref_stds
    )

    # --- Per-feature anomalies over time: ONLY 13.10.2025 ---
    plot_feature_anomalies_over_time(
        log_path=os.path.join(OUT_DIR, "predictions_log.csv"),
        ref_means=None,
        ref_stds=None,
        window_minutes=15,         # 15-min buckets look clean for a full day
        smooth_points=5,
        hours_back=None,           # ignored because start_at/end_at are set
        start_at="2025-10-13 00:00:00",
        end_at="2025-10-13 23:59:59",
    )

if __name__ == "__main__":
    main()





# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# app/model.py
# ------------------------------------------------------------
# Wind Turbine Anomaly Detector (IsolationForest)
# Features: temperature, humidity, sound_volume
# Purpose: minimal wrapper to train, save/load, and predict
# Output: models/turbine_iforest.pkl (model + scaler + meta)
# ------------------------------------------------------------
from __future__ import annotations

import os
from typing import Dict, List, Optional

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler


class TurbineAnomalyDetector:
    """
    Minimal anomaly detector with:
      - StandardScaler for numeric stability
      - IsolationForest for unsupervised anomaly detection
      - score_samples() used for anomaly_score (inverted so higher = more anomalous)
      - Save/load including metadata (features, params, threshold, version)
    """

    feature_names: List[str] = ["temperature", "humidity", "sound_volume"]

    def __init__(
        self,
        contamination: float = 0.05,
        n_estimators: int = 200,
        random_state: int = 42,
        threshold: float = 0.0,
        version: str = "iforest-1.0",
    ):
        self.contamination = float(contamination)
        self.n_estimators = int(n_estimators)
        self.random_state = int(random_state)
        self.threshold = float(threshold)       # can be updated after Val search in train_eval.py
        self.version = str(version)

        self.model: Optional[IsolationForest] = None
        self.scaler: Optional[StandardScaler] = None

    # ---------------------------
    # Training / inference
    # ---------------------------
    def train(self, X: pd.DataFrame) -> None:
        """Fit scaler + model on provided DataFrame."""
        self._check_cols(X)
        Xn = X[self.feature_names].to_numpy(dtype=float, copy=False)

        self.scaler = StandardScaler().fit(Xn)
        self.model = IsolationForest(
            contamination=self.contamination,
            n_estimators=self.n_estimators,
            random_state=self.random_state,
            n_jobs=-1,
        )
        self.model.fit(self.scaler.transform(Xn))

    def predict(self, X: pd.DataFrame) -> Dict[str, np.ndarray]:
        """
        Returns:
          - is_anomaly: int array {0,1}
          - anomaly_score: float array (higher = more anomalous)
        """
        if self.model is None or self.scaler is None:
            raise RuntimeError("Model not trained/loaded.")
        self._check_cols(X)
        Z = self.scaler.transform(X[self.feature_names].to_numpy(dtype=float, copy=False))

        # scikit-learn: lower score_samples -> more anomalous
        # invert so that higher means more anomalous (intuitive for plots/thresholding)
        anomaly_score = -self.model.score_samples(Z)
        is_anomaly = (self.model.predict(Z) == -1).astype(int)

        return {"is_anomaly": is_anomaly, "anomaly_score": anomaly_score}

    def predict_row(self, temperature: float, humidity: float, sound_volume: float) -> Dict[str, float]:
        """
        Convenience method for single-row predictions (useful for API).
        """
        if self.model is None or self.scaler is None:
            raise RuntimeError("Model not trained/loaded.")
        x = np.array([[float(temperature), float(humidity), float(sound_volume)]], dtype=float)
        z = self.scaler.transform(x)
        score = float(-self.model.score_samples(z)[0])
        label = int(self.model.predict(z)[0] == -1)
        return {"is_anomaly": label, "anomaly_score": score}

    # ---------------------------
    # Persistence / metadata
    # ---------------------------
    def save(self, path: str = "models/turbine_iforest.pkl") -> None:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        payload = {
            "model": self.model,
            "scaler": self.scaler,
            "meta": {
                "feature_names": self.feature_names,
                "contamination": self.contamination,
                "n_estimators": self.n_estimators,
                "random_state": self.random_state,
                "threshold": self.threshold,
                "version": self.version,
            },
        }
        joblib.dump(payload, path)

    def load(self, path: str = "models/turbine_iforest.pkl") -> None:
        obj = joblib.load(path)
        self.model = obj["model"]
        self.scaler = obj["scaler"]
        meta = obj.get("meta", {})

        # Restore metadata if present, otherwise keep current defaults
        self.feature_names = meta.get("feature_names", self.feature_names)
        self.contamination = float(meta.get("contamination", self.contamination))
        self.n_estimators = int(meta.get("n_estimators", self.n_estimators))
        self.random_state = int(meta.get("random_state", self.random_state))
        self.threshold = float(meta.get("threshold", self.threshold))
        self.version = str(meta.get("version", self.version))

    def get_meta(self) -> Dict[str, object]:
        """Expose minimal metadata for /model/info or logs."""
        return {
            "version": self.version,
            "threshold": self.threshold,
            "features": list(self.feature_names),
            "contamination": self.contamination,
            "n_estimators": self.n_estimators,
            "random_state": self.random_state,
        }

    # ---------------------------
    # Utilities
    # ---------------------------
    def set_threshold(self, threshold: float) -> None:
        self.threshold = float(threshold)

    def _check_cols(self, X: pd.DataFrame) -> None:
        missing = [c for c in self.feature_names if c not in X.columns]
        if missing:
            raise ValueError(f"Missing required features: {missing}")





# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# app/api.py
# ------------------------------------------------------------
# Flask REST API for Anomaly Scoring (Standardized Service)
# GET /health, /model/info, /metrics
# POST /predict -> {timestamp_utc, is_anomaly, anomaly_score}
# Extras: minimal metrics + CSV prediction log
# Flask 3.x compatible; loads model at import time.
# ------------------------------------------------------------
from __future__ import annotations

import os, csv, time, json
from datetime import datetime, timezone
from collections import defaultdict
from typing import Dict, Any, Tuple

import pandas as pd
from flask import Flask, request, jsonify

from app.model import TurbineAnomalyDetector

# ---- Paths
MODEL_PATH = os.getenv("MODEL_PATH", "models/turbine_iforest.pkl")
OUT_DIR = "app/outputs"
LOG_PATH = os.path.join(OUT_DIR, "predictions_log.csv")

# ---- Contract & ranges (single source of truth)
REQUIRED_FIELDS: Dict[str, Dict[str, float | tuple]] = {
    "temperature":  {"type": (int, float), "min": -50.0, "max": 120.0, "units": "°C"},
    "humidity":     {"type": (int, float), "min": 0.0,   "max": 100.0, "units": "%"},
    "sound_volume": {"type": (int, float), "min": 0.0,   "max": 200.0, "units": "arb"},
}

# ---- App state
app = Flask(__name__)
det = TurbineAnomalyDetector()
MODEL_LOADED = False
METRICS = defaultdict(int)   # requests, 4xx, 5xx, preds
LAT_SUM = 0.0


# ---------------------------
# Helpers
# ---------------------------
def _ensure_model() -> None:
    global MODEL_LOADED
    try:
        det.load(MODEL_PATH)
        MODEL_LOADED = True
    except Exception:
        MODEL_LOADED = False


def _coerce_float(x) -> float:
    if isinstance(x, (int, float)):
        return float(x)
    if isinstance(x, str):
        return float(x.strip())
    raise ValueError("not a number")


def _validate_payload(payload: dict) -> Tuple[dict, list[str]]:
    errors, clean = [], {}
    if not isinstance(payload, dict):
        return {}, ["payload must be a JSON object"]
    for k, spec in REQUIRED_FIELDS.items():
        if k not in payload:
            errors.append(f"missing field: {k}")
            continue
        try:
            v = _coerce_float(payload[k])
        except Exception:
            errors.append(f"{k}: must be numeric")
            continue
        if v < spec["min"] or v > spec["max"]:
            errors.append(f"{k}: out of range [{spec['min']}, {spec['max']}] {spec['units']}")
        clean[k] = v
    return clean, errors


def _log_prediction(row: Dict[str, Any], is_anom: bool, score: float) -> None:
    os.makedirs(OUT_DIR, exist_ok=True)
    header = ["timestamp_utc", "temperature", "humidity", "sound_volume", "is_anomaly", "anomaly_score"]
    write_header = not os.path.exists(LOG_PATH)
    with open(LOG_PATH, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=header)
        if write_header:
            w.writeheader()
        w.writerow({
            "timestamp_utc": datetime.now(timezone.utc).replace(microsecond=0).isoformat(),
            "temperature": row["temperature"],
            "humidity": row["humidity"],
            "sound_volume": row["sound_volume"],
            "is_anomaly": int(is_anom),
            "anomaly_score": float(score),
        })


# Load once at import (Flask 3.x friendly)
_ensure_model()


# ---------------------------
# Endpoints
# ---------------------------
@app.get("/health")
def health():
    return jsonify({
        "status": "healthy" if MODEL_LOADED else "degraded",
        "model_loaded": MODEL_LOADED,
        "time_utc": datetime.now(timezone.utc).isoformat()
    })


@app.get("/model/info")
def model_info():
    if not MODEL_LOADED:
        return jsonify({"error": "model not loaded"}), 500
    # If model implements get_meta(), expose that; otherwise basic fields
    try:
        meta = det.get_meta()
    except Exception:
        meta = {
            "features": det.feature_names,
            "contamination": det.contamination,
            "n_estimators": det.n_estimators,
            "random_state": det.random_state,
            "version": "unknown",
            "threshold": 0.0,
        }
    return jsonify({
        "model_type": "IsolationForest",
        **meta
    })


@app.get("/metrics")
def metrics():
    avg_ms = (LAT_SUM / max(1, METRICS["requests"])) * 1000.0
    return jsonify({
        "requests_total": METRICS["requests"],
        "requests_4xx": METRICS["4xx"],
        "requests_5xx": METRICS["5xx"],
        "predictions_total": METRICS["preds"],
        "avg_latency_ms": round(avg_ms, 3)
    })


@app.post("/predict")
def predict():
    start = time.perf_counter()
    METRICS["requests"] += 1
    try:
        if not MODEL_LOADED:
            METRICS["5xx"] += 1
            return jsonify({"error": "model not loaded"}), 500

        # Try JSON first
        payload = request.get_json(silent=True)
        # Fallback to raw or form (for curl -d "x=1" cases)
        if payload is None:
            try:
                payload = json.loads(request.get_data(cache=False, as_text=True))
            except Exception:
                payload = {}
        if not payload and request.form:
            payload = request.form.to_dict(flat=True)

        clean, errors = _validate_payload(payload)
        if errors:
            METRICS["4xx"] += 1
            return jsonify({"error": "validation_failed", "details": errors}), 400

        df = pd.DataFrame([clean], columns=list(REQUIRED_FIELDS.keys()))
        res = det.predict(df)
        is_anom = bool(res["is_anomaly"][0])
        score = float(res["anomaly_score"][0])

        METRICS["preds"] += 1
        _log_prediction(clean, is_anom, score)

        return jsonify({
            "timestamp_utc": datetime.now(timezone.utc).replace(microsecond=0).isoformat(),
            "inputs": clean,
            "is_anomaly": is_anom,
            "anomaly_score": score
        })
    except Exception:
        METRICS["5xx"] += 1
        return jsonify({"error": "internal error"}), 500
    finally:
        global LAT_SUM
        LAT_SUM += (time.perf_counter() - start)


if __name__ == "__main__":
    # Optional: auto-train if missing
    if not os.path.exists(MODEL_PATH):
        try:
            from app.train_eval import main as train_then_save
            train_then_save()
        except Exception:
            pass
        _ensure_model()
    app.run(host="0.0.0.0", port=5000)






# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# app/visualize_from_csv.py
# ------------------------------------------------------------
# Visualize anomalies over time from the live API log (PNG only).
# Input : app/outputs/predictions_log.csv
# Output: app/outputs/anomalies_over_time.png
# - EU time axis: DD-MM-YY HH:MM
# - Configurable bucket minutes via env VIZ_BUCKET_MIN (default: 15)
# - Optional day filter via env VIZ_DAY_FILTER ("DD-MM" or "DD-MM-YY")
# ------------------------------------------------------------
from __future__ import annotations

import os
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.dates import DateFormatter

OUT_DIR  = "app/outputs"
SAVE_DIR = "app/outputs"
LOG_PATH = os.path.join(OUT_DIR, "predictions_log.csv")

# ENV configuration
BUCKET_MIN = int(os.getenv("VIZ_BUCKET_MIN", "15"))
DAY_FILTER = os.getenv("VIZ_DAY_FILTER", "").strip() or None  # e.g. "13-10" or "13-10-25"

def _save(fig: plt.Figure, base: str):
    os.makedirs(SAVE_DIR, exist_ok=True)
    fig.savefig(os.path.join(SAVE_DIR, f"{base}.png"), bbox_inches="tight", dpi=150)
    plt.close(fig)

def anomalies_over_time(df: pd.DataFrame):
    """
    Line plot of temperature (°C), humidity (%) and sound_volume (arb)
    over time using BUCKET_MIN-minute buckets.
    - X-axis formatted as DD-MM-YY HH:MM
    - Optional DAY_FILTER limits the shown window
    - Buckets with any anomaly are marked with 'x'
    """
    if "timestamp_utc" not in df.columns:
        raise ValueError("CSV must include 'timestamp_utc' column (UTC ISO).")

    # Parse & coerce numerics
    g = df.copy()
    g["timestamp_utc"] = pd.to_datetime(g["timestamp_utc"], utc=True, errors="coerce")
    for col in ["temperature", "humidity", "sound_volume", "is_anomaly"]:
        if col in g.columns:
            g[col] = pd.to_numeric(g[col], errors="coerce")
    g = g.dropna(subset=["timestamp_utc"])
    if g.empty:
        # placeholder
        fig = plt.figure(figsize=(12, 5))
        plt.title("Anomalies over time — no data")
        _save(fig, "anomalies_over_time")
        return

    # Optional day filter
    if DAY_FILTER:
        fmt = "%d-%m-%y" if len(DAY_FILTER.split("-")) == 3 else "%d-%m"
        mask = g["timestamp_utc"].dt.strftime(fmt) == DAY_FILTER
        g = g.loc[mask].copy()

    if g.empty:
        fig = plt.figure(figsize=(12, 5))
        plt.title(f"Anomalies over time — no data for {DAY_FILTER}")
        _save(fig, "anomalies_over_time")
        return

    # Resample
    bucket = f"{BUCKET_MIN}T"
    g = g.set_index("timestamp_utc").sort_index()
    agg = g.resample(bucket).mean(numeric_only=True)

    # anomaly presence per bucket
    if "is_anomaly" in g.columns:
        anom_flag = g["is_anomaly"].resample(bucket).max().reindex(agg.index).fillna(0).astype(int)
    else:
        anom_flag = pd.Series(0, index=agg.index)

    # Plot
    fig, ax1 = plt.subplots(figsize=(12, 5))

    # Left axis: temperature & humidity
    if "temperature" in agg.columns:
        ax1.plot(agg.index, agg["temperature"], linewidth=1.8, label="temperature (°C)")
    if "humidity" in agg.columns:
        ax1.plot(agg.index, agg["humidity"], linewidth=1.8, label="humidity (%)")
    ax1.set_xlabel("Zeit (DD-MM-YY HH:MM)")
    ax1.set_ylabel("Temp / Humidity")
    ax1.xaxis.set_major_formatter(DateFormatter("%d-%m-%y %H:%M"))
    fig.autofmt_xdate(rotation=20)

    # Right axis: sound_volume (dashed)
    handles, labels = ax1.get_legend_handles_labels()
    if "sound_volume" in agg.columns:
        ax2 = ax1.twinx()
        ax2.plot(agg.index, agg["sound_volume"], linestyle="--", linewidth=1.8, label="sound_volume (arb)")
        ax2.set_ylabel("Sound volume")
        h2, l2 = ax2.get_legend_handles_labels()
        handles += h2; labels += l2

    # Anomaly markers at top
    if anom_flag.any():
        y_top = ax1.get_ylim()[1]
        ax1.scatter(agg.index[anom_flag == 1], np.full((anom_flag == 1).sum(), y_top * 0.98),
                    marker="x", s=40, label="anomaly")
        handles, labels = ax1.get_legend_handles_labels()

    ax1.legend(handles, labels, loc="upper left")
    title_suffix = f" — {DAY_FILTER}" if DAY_FILTER else ""
    plt.title(f"Anomalies over time ({BUCKET_MIN} min buckets){title_suffix}")
    plt.tight_layout()
    _save(fig, "anomalies_over_time")

def main():
    if not os.path.exists(LOG_PATH):
        raise FileNotFoundError(f"Missing {LOG_PATH}. Start the API + sender to generate it.")
    os.makedirs(SAVE_DIR, exist_ok=True)
    df = pd.read_csv(LOG_PATH)

    anomalies_over_time(df)

    # Quick console summary
    anomalies = int((pd.to_numeric(df.get("is_anomaly"), errors="coerce") == 1).sum())
    print(f"[viz] rows={len(df)} anomalies={anomalies} rate={(anomalies/max(1,len(df))):.2%}")
    print(f"[viz] saved PNG → {os.path.abspath(os.path.join(SAVE_DIR, 'anomalies_over_time.png'))}")

if __name__ == "__main__":
    main()






# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# app/sender.py
# ------------------------------------------------------------
# Stream Simulator (Fictional Sample Data → REST API)
# Sends JSON to /predict periodically; supports SENDER_COUNT to auto-stop.
# Aligned with API contract & ranges.
# ------------------------------------------------------------
from __future__ import annotations
import os, time, random, math, signal, sys
import requests

API_URL       = os.getenv("API_URL", "http://localhost:5000/predict")
SENDER_COUNT  = int(os.getenv("SENDER_COUNT", "0"))   # 0 = infinite
INTERVAL_SEC  = float(os.getenv("SENDER_INTERVAL_SEC", "0.5"))
TIMEOUT_SEC   = float(os.getenv("SENDER_TIMEOUT_SEC", "3"))
ANOM_RATE     = float(os.getenv("SENDER_ANOM_RATE", "0.05"))  # 5% anomalies

# Valid ranges per API contract
RANGES = {
    "temperature":  (-50.0, 120.0),
    "humidity":     (0.0,   100.0),
    "sound_volume": (0.0,   200.0),
}

def _clip(v: float, lo: float, hi: float) -> float:
    return min(hi, max(lo, float(v)))

def _rnd(mu: float, sigma: float) -> float:
    return random.gauss(mu, sigma)

def sample() -> dict:
    """
    Generate one reading. Mostly normal ops with occasional anomalies.
    Values are clipped to API-accepted ranges to avoid 4xx responses.
    """
    # Normal operating point
    x = {
        "temperature": 25 + _rnd(0, 3),
        "humidity":    65 + _rnd(0, 10),
        "sound_volume": 0.6 + _rnd(0, 0.12),
    }

    # Inject anomaly with probability ANOM_RATE
    if random.random() < ANOM_RATE:
        x["temperature"]  = random.choice([45 + _rnd(0, 4), 10 + _rnd(0, 4)])
        x["humidity"]     = random.choice([20 + _rnd(0, 8), 95 + _rnd(0, 4)])
        x["sound_volume"] = random.choice([1.4 + _rnd(0, 0.25), 0.05 + _rnd(0, 0.02)])

    # Clip to contract ranges and round for pretty logs
    for k, (lo, hi) in RANGES.items():
        x[k] = round(_clip(x[k], lo, hi), 3)

    return x

def _install_sigint_handler():
    def _handler(signum, frame):
        print("\n[sender] received interrupt, exiting.")
        sys.exit(0)
    signal.signal(signal.SIGINT, _handler)

def main():
    _install_sigint_handler()
    sess = requests.Session()

    # Optional quick health probe
    try:
        r = sess.get(API_URL.replace("/predict", "/health"), timeout=TIMEOUT_SEC)
        if r.ok:
            print(f"[sender] health: {r.json().get('status', 'unknown')}")
        else:
            print(f"[sender] health check failed: HTTP {r.status_code}")
    except Exception as e:
        print(f"[sender] health check error: {e}")

    count = 0
    while True:
        payload = sample()
        try:
            r = sess.post(API_URL, json=payload, timeout=TIMEOUT_SEC)
            if r.ok:
                data = r.json()
                print(f"[{r.status_code}] anom={data.get('is_anomaly')} score={data.get('anomaly_score'):.4f} inputs={payload}")
            else:
                # Print server error body for visibility
                try:
                    print(f"[{r.status_code}] {r.json()}")
                except Exception:
                    print(f"[{r.status_code}] {r.text[:200]}")
        except Exception as e:
            print(f"[sender] send error: {e}")

        count += 1
        if SENDER_COUNT and count >= SENDER_COUNT:
            break
        time.sleep(INTERVAL_SEC)

if __name__ == "__main__":
    main()




# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# Dockerfile
# ------------------------------------------------------------
# Minimal image for Flask API runtime
# Trains model on first start if missing.
# ------------------------------------------------------------
    
FROM python:3.10-slim
WORKDIR /app
RUN apt-get update && apt-get install -y --no-install-recommends gcc && rm -rf /var/lib/apt/lists/*
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app ./app
COPY models ./models
ENV PYTHONPATH=/app
ENV MODEL_PATH=models/turbine_iforest.pkl
EXPOSE 5000
CMD ["python", "-m", "app.api"]




# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# docker-compose.yml
# ------------------------------------------------------------
# Orchestrates a two-service demo:
#   api    : Flask REST service (/predict, /health, /metrics)
#   sender : Sidecar that streams fictional sample data to the API
# Purpose:
#   - Show data ingestion over a standardized API (Task 1)
#   - Persist models/outputs to host for slides and inspection
# Usage:
#   - Start: `docker compose up --build`
#   - Stop : `docker compose down`
# ------------------------------------------------------------

version: "3.9"
services:
  api:
    build: .
    container_name: turbine-api
    environment:
      MODEL_PATH: models/turbine_iforest.pkl
      PYTHONUNBUFFERED: "1"
    ports: ["5000:5000"]
    volumes:
      - ./models:/app/models
      - ./app/outputs:/app/app/outputs
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; print(requests.get('http://localhost:5000/health', timeout=2).status_code)"]
      interval: 10s
      timeout: 3s
      retries: 6
      start_period: 10s
    restart: unless-stopped

  sender:
    build: .
    container_name: turbine-sender
    depends_on:
      api:
        condition: service_healthy
    environment:
      API_URL: http://api:5000/predict
      SENDER_COUNT: "0"     # set to a number to auto-stop
      PYTHONUNBUFFERED: "1"
    command: ["python", "-m", "app.sender"]
    volumes:
      - ./app/outputs:/app/app/outputs
    restart: unless-stopped



# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# tests/test.py
# ------------------------------------------------------------
# End-to-End tests (minimal & robust)
# - Trains model if missing
# - Checks /health, /model/info, /metrics, /predict
# - Generates log rows and validates CSV schema (timestamp OR timestamp_utc)
# - Runs CSV visualizer and checks key artifacts
# ------------------------------------------------------------
import os, sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import math, random, pandas as pd

MODEL_PATH = "models/turbine_iforest.pkl"
OUT_DIR = "app/outputs"
LOG_PATH = os.path.join(OUT_DIR, "predictions_log.csv")

def _gauss(mu, sigma): return random.gauss(mu, sigma)
def sample_ok():
    return {"temperature": 25 + _gauss(0,3),
            "humidity": 65 + _gauss(0,10),
            "sound_volume": 0.6 + _gauss(0,0.12)}

def ensure_model():
    from app.train_eval import main as train_main
    need = False

    if not os.path.exists(MODEL_PATH):
        need = True

    required_pngs = [
        "metrics_table.png",
        "heatmaps_grid.png",
        "learning_dashboard_2x2.png",
    ]
    for f in required_pngs:
        if not os.path.exists(os.path.join(OUT_DIR, f)):
            need = True
            break

    if need:
        print("[test] building artifacts via training ...")
        train_main()
        assert os.path.exists(MODEL_PATH), "Model training failed."

def make_app():
    from app.api import app, _ensure_model
    _ensure_model()
    return app

def run_tests():
    ensure_model()
    app = make_app()
    client = app.test_client()

    # /health
    r = client.get("/health"); assert r.status_code == 200
    j = r.get_json(); assert j.get("model_loaded") is True
    print("[test] /health OK")

    # /model/info
    r = client.get("/model/info"); assert r.status_code == 200
    j = r.get_json()
    assert j.get("model_type") == "IsolationForest"
    feats = j.get("features") or j.get("feature_names")
    assert feats is not None and set(feats) == {"temperature","humidity","sound_volume"}
    print("[test] /model/info OK")

    # /metrics
    r = client.get("/metrics"); assert r.status_code == 200
    j = r.get_json()
    for k in ["requests_total","requests_4xx","requests_5xx","predictions_total","avg_latency_ms"]:
        assert k in j
    print("[test] /metrics OK")

    # /predict — valid
    r = client.post("/predict", json=sample_ok()); assert r.status_code == 200
    p = r.get_json()
    assert isinstance(p.get("anomaly_score"), (int,float))
    assert math.isfinite(float(p["anomaly_score"])) and -10.0 < float(p["anomaly_score"]) < 10.0
    assert isinstance(p.get("is_anomaly"), (bool,int))
    ts = p.get("timestamp") or p.get("timestamp_utc")
    assert isinstance(ts, str) and len(ts) >= 10
    print("[test] /predict OK (valid)")

    # populate log
    for _ in range(8):
        client.post("/predict", json=sample_ok())

    # /predict — invalid -> 400
    r = client.post("/predict", json={"temperature":25.0,"humidity":60.0})
    assert r.status_code == 400
    print("[test] /predict OK (invalid payload → 400)")

    # predictions_log.csv (accept timestamp OR timestamp_utc)
    assert os.path.exists(LOG_PATH), "predictions log missing"
    df_log = pd.read_csv(LOG_PATH)
    cols = set(df_log.columns)
    schema_a = {"timestamp","temperature","humidity","sound_volume","is_anomaly","anomaly_score"}
    schema_b = {"timestamp_utc","temperature","humidity","sound_volume","is_anomaly","anomaly_score"}
    assert schema_a.issubset(cols) or schema_b.issubset(cols), f"log schema mismatch: {cols}"
    print(f"[test] log OK ({len(df_log)} rows)")

    # Visualization from CSV (best-effort)
    try:
        from app.visualize_from_csv import main as viz_main
        viz_main()
        ao = os.path.join(OUT_DIR, "anomalies_over_time.png")
        assert os.path.exists(ao), "anomalies_over_time.png not created"
        print("[test] visualize_from_csv OK")
    except Exception as e:
        print("[test] visualize_from_csv skipped:", e)

    # Training/Eval artifacts
    for f in ["metrics_table.png","heatmaps_grid.png","learning_dashboard_2x2.png"]:
        assert os.path.exists(os.path.join(OUT_DIR, f)), f"missing {f}"

    mt = os.path.join(OUT_DIR, "metrics_table.csv")
    assert os.path.exists(mt), "missing metrics_table.csv"
    df_mt = pd.read_csv(mt)
    assert {"Split","Accuracy","Precision","Recall","F1","ROC_AUC"}.issubset(df_mt.columns)

    print("\n[test] PASS  All checks succeeded.")

if __name__ == "__main__":
    run_tests()



# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# requirements.txt (python 3.10.9)
# ------------------ 
# pip freeze
# ------------------ 
blinker==1.9.0
certifi==2025.10.5
charset-normalizer==3.4.3
click==8.3.0
colorama==0.4.6
contourpy==1.3.2
cycler==0.12.1
Flask==3.1.2
fonttools==4.60.1
idna==3.11
itsdangerous==2.2.0
Jinja2==3.1.6
joblib==1.5.2
kiwisolver==1.4.9
MarkupSafe==3.0.3
matplotlib==3.10.7
numpy==2.2.6
packaging==25.0
pandas==2.3.3
pillow==11.3.0
pyparsing==3.2.5
python-dateutil==2.9.0.post0
pytz==2025.2
requests==2.32.5
scikit-learn==1.7.2
scipy==1.15.3
six==1.17.0
threadpoolctl==3.6.0
tzdata==2025.2
urllib3==2.5.0
Werkzeug==3.1.3





# ------------------------------------------------------------
# ------------------------------------------------------------
# ------------------------------------------------------------
# Mermaid chart
# ------------------------------------------------------------
# ------------------------------------------------------------
---
config:
  theme: neutral
  look: classic
  layout: dagre
---
flowchart LR
    N1["**1.
    Concept &amp; Architecture**
    ---------------------------------- 
    Task: 
    detect turbine anomalies
    ---------------------------------- 
    *README* + system diagram"] --> N2[("**2.
    Data Source & Simulation**
    ----------------------------------
    Fictional sample data: 
    temp, humidity, sound
    ----------------------------------
    70/10/20 split 
    ----------------------------------
    *app/train_eval.py*")]
    N2 --> N3[("**3.<br>Train &amp; Save Simple Model**
    ----------------------------------
    IsolationForest
    ----------------------------------
    Save model file:
    *models/turbine_iforest.pkl*
    *app/model.py*")]
    N3 --> N4[("**4. 
    Prediction API (REST)**
    ----------------------------------
    /predict /health 
    /model/info /metrics
    ----------------------------------
    Loads: *models/turbine_iforest.pkl* 
    on start
    ----------------------------------
    Logs: *app/outputs/predictions_log.csv*
    ----------------------------------
    *app/api.py*")]
    N4 --> N5[("**5.
    Data Ingestion & Streaming**
    ----------------------------------
    *app/sender.py* → HTTP POST /predict (JSON)
    ----------------------------------
    *visualize_from_csv.py* → PNGs from CSV log")]
    N5 --> N6[("**6.
    Reproducible Run 
    (Container + Tests)**
    ---------------------------------- 
    *Dockerfile* + 
    *docker-compose.yml*
    ----------------------------------
    API check: *test.py*")]
    N1@{ shape: cyl}
     N1:::yellow
     N2:::orange
     N3:::red
     N4:::blue
     N5:::teal
     N6:::green
    classDef yellow fill:#FFF5B1,stroke:#E6C14A,stroke-width:2,color:#111
    classDef orange fill:#FFC98B,stroke:#F2A552,stroke-width:2,color:#111
    classDef red    fill:#FFB3B8,stroke:#F28A92,stroke-width:2,color:#111
    classDef blue   fill:#AECBFA,stroke:#7DA6F2,stroke-width:2,color:#111
    classDef teal   fill:#B3E5FC,stroke:#72B6F2,stroke-width:2,color:#111
    classDef green  fill:#C7F3D6,stroke:#7BC89A,stroke-width:2,color:#111
    style N1 color:#000000,fill:#FFF9C4

